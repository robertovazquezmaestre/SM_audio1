{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "049d5c18",
   "metadata": {},
   "source": [
    "# Tarea audio 2\n",
    "Autor: Roberto Vázquez Maestre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11fa993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import IPython\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789c4b1c",
   "metadata": {},
   "source": [
    "## Definiciones\n",
    "\n",
    "- **Frecuencia de muestreo:** Es la cantidad de veces por segundo que se mide una señal analógica para convertirla en digital. Determina qué tan finamente se representa el tiempo de la señal y establece el límite máximo de frecuencia que puede capturar.  \n",
    "\n",
    "- **Aliasing:** Es un fenómeno de distorsión que ocurre cuando la señal se muestrea a una frecuencia insuficiente. Dando lugar a que esta ni pueda ser reconstruidad de forma correcta.\n",
    "\n",
    "- **Profundidad de bits:** Es la cantidad de bits utilizados para representar cada muestra de la señal. Determina la resolución de amplitud de la señal digital y afecta directamente el nivel de ruido de cuantización y la fidelidad del audio.  \n",
    "\n",
    "- **Ancho de banda:** Es el rango de frecuencias que una señal puede contener o que un sistema puede transmitir. En audio digital, está limitado por la mitad de la frecuencia de muestreo (teorema de Nyquist).  \n",
    "\n",
    "- **Tasa de bits:** Es la cantidad de datos que se procesan o transmiten por segundo en un archivo digital. Depende de la frecuencia de muestreo, la profundidad de bits y el número de canales, y define la calidad y tamaño del archivo digital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed0e436",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "audio_input_path_est = os.path.join(cwd, os.path.join('Audio_input'))  \n",
    "audio_input_path_mono = os.path.join(cwd, os.path.join('Audio_output'))\n",
    "audio_output_path = os.path.join(cwd, os.path.join('Audio_output')) \n",
    "print(f'Directorios con los audios de entrada: {audio_input_path_est} y {audio_input_path_mono}')\n",
    "print(f'Directorio donde guardaremos los audios generados: {audio_output_path}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329135a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(audio_input_path_est, 'game_of_thrones.wav')\n",
    "sample_rate, audio_data_est = wavfile.read(filename)\n",
    "\n",
    "filename = os.path.join(audio_input_path_mono, 'game_of_thrones_mono.wav')\n",
    "sample_rate, audio_data_mono = wavfile.read(filename)\n",
    "\n",
    "print(f'Frecuencia de muestreo (sample rate): {sample_rate/1000} kHz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b62fb46",
   "metadata": {},
   "source": [
    "Aquí se muestra la gráfica en el dominio del tiempo para el audio mono y estéreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e174f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = os.path.join(audio_input_path_est, 'game_of_thrones.wav')\n",
    "sample_rate, audio_data_est = wavfile.read(filename)\n",
    "\n",
    "filename = os.path.join(audio_input_path_mono, 'game_of_thrones_mono.wav')\n",
    "sample_rate, audio_data_mono = wavfile.read(filename)\n",
    "\n",
    "print(f'Frecuencia de muestreo (sample rate): {sample_rate/1000} kHz')\n",
    "\n",
    "if len(audio_data_est.shape) > 1:\n",
    "    audio_data_est = audio_data_est[:, 0]\n",
    "\n",
    "t_est = np.arange(len(audio_data_est)) / sample_rate\n",
    "t_mono = np.arange(len(audio_data_mono)) / sample_rate\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "\n",
    "end = 1000\n",
    "\n",
    "# Señal estéreo (visualizamos solo el canal 1)\n",
    "ax[0].plot(t_est[:end], audio_data_est[:end], marker='o', markevery=20)\n",
    "ax[0].set_title('Audio estéreo (canal 1) en el dominio del tiempo')\n",
    "ax[0].set_ylabel('Amplitud')\n",
    "ax[0].grid(True)\n",
    "\n",
    "# Señal mono\n",
    "ax[1].plot(t_mono[:end], audio_data_mono[:end], c='tab:red', marker='o', markevery=20)\n",
    "ax[1].set_title('Audio mono en el dominio del tiempo')\n",
    "ax[1].set_xlabel('Tiempo (s)')\n",
    "ax[1].set_ylabel('Amplitud')\n",
    "ax[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40db25c",
   "metadata": {},
   "source": [
    "Se realiza la Transformada rápida de Fourier (FFT) sobre el audio mono. \n",
    "\n",
    "Se convierte el audio a mono para simplificar el análisis y se aplica la FFT para ver la composición en frecuencia del sonido, es decir, qué tonos y sonidos forman la señal y cuánto pesan, algo que no se ve en la forma de onda en el tiempo. Esto ayuda a detectar ruidos, identificar sonidos predominantes y mejorar o modificar el audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a05446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n = len(audio_data_mono)\n",
    "Fs = sample_rate\n",
    "\n",
    "ch_Fourier = np.fft.fft(audio_data_mono)\n",
    "\n",
    "abs_ch_Fourier = np.abs(ch_Fourier[:n//2])\n",
    "\n",
    "frequencies = np.linspace(0, Fs/2, n//2)\n",
    "\n",
    "# Graficamos\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(frequencies, abs_ch_Fourier)\n",
    "plt.title('Espectro de Frecuencia - Audio Mono')\n",
    "plt.ylabel('Amplitud')\n",
    "plt.xlabel('Frecuencia (Hz)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293c2868",
   "metadata": {},
   "source": [
    "Se calcula la energia del espectro y se elige un epsilon por el cual se hace el corte. En este caso se ha elegido el epsilon de .041, debido a que esto elimina algunas frecuencias altas de poca energía, donde no hay mucho contenido importante, dejando solo la parte principal del espectro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85acf297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos diferentes epsilons (energía que NO conservamos)\n",
    "eps_values = [1e-5, .02, .041, .063, .086, .101, .123]\n",
    "\n",
    "# Elegimos uno (puedes ir cambiando el índice)\n",
    "eps = eps_values[2]\n",
    "print(f'Epsilon: {eps}')\n",
    "\n",
    "# Valor de corte de energía acumulada\n",
    "thr_spec_energy = (1 - eps) * np.sum(abs_ch_Fourier)\n",
    "print(f'Valor de corte para la energía del espectro: {thr_spec_energy}')\n",
    "\n",
    "# Energía acumulada\n",
    "spec_energy = np.cumsum(abs_ch_Fourier)\n",
    "\n",
    "# Máscara booleana\n",
    "frequencies_to_remove = spec_energy > thr_spec_energy\n",
    "print(f'Máscara: {frequencies_to_remove}')\n",
    "\n",
    "# Índice donde se alcanza el umbral\n",
    "cut_index = np.argmax(frequencies_to_remove)\n",
    "\n",
    "# Frecuencia de corte\n",
    "f0 = frequencies[cut_index]\n",
    "print(f'Frecuencia de corte f0 (Hz): {int(f0)}')\n",
    "\n",
    "# Graficamos\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(frequencies, abs_ch_Fourier)\n",
    "plt.axvline(f0, color='r', label=f'f0 = {int(f0)} Hz')\n",
    "plt.ylabel('Amplitud')\n",
    "plt.xlabel('Frecuencia (Hz)')\n",
    "plt.title('Espectro y frecuencia de corte')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba89736",
   "metadata": {},
   "source": [
    "Se comprime la onda y se guarda en un nuevo archivo con el audio comprimido. El factor de downsampling se calcula a partir del sample_rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f94e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el factor D de downsampling.\n",
    "D = int(Fs / f0)\n",
    "print(f'Factor de downsampling: {D}')\n",
    "\n",
    "# Obtenemos los nuevos datos (slicing with stride).\n",
    "new_data = audio_data_mono[::D]\n",
    "\n",
    "# Definimos el nombre del audio comprimido generado.\n",
    "wav_compressed_file = \"game_of_thrones_compressed.wav\"\n",
    "\n",
    "# Escribimos los datos a un archivo de tipo wav.\n",
    "wavfile.write(\n",
    "    filename=os.path.join(audio_output_path, wav_compressed_file),\n",
    "    rate=int(Fs/D),\n",
    "    data=new_data\n",
    ")\n",
    "\n",
    "# Cargamos el nuevo archivo.\n",
    "new_sample_rate, new_audio_data = wavfile.read(filename=os.path.join(audio_output_path, wav_compressed_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861e8c52",
   "metadata": {},
   "source": [
    "Se muestan los epectogramas de los dos archivos el normal y el comprimido. COmo se puede ver en el comprimido hay muchas más rayas lo que indica que el audio esta mas comprimido y no es del todo continuo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114e4f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "Pxx, freqs, bins, im = ax[0].specgram(audio_data_mono, NFFT=1024, Fs=sample_rate, noverlap=512)\n",
    "ax[0].set_title('Espectograma del audio original')\n",
    "ax[0].set_ylabel('Frecuencia (Hz)')\n",
    "ax[0].grid(True)\n",
    "\n",
    "Pxx, freqs, bins, im = ax[1].specgram(new_audio_data, NFFT=1024, Fs=new_sample_rate, noverlap=512)\n",
    "ax[1].set_title('Espectrograma del audio reducido/comprimido')\n",
    "ax[1].set_xlabel('Tiempo (s)')\n",
    "ax[1].set_ylabel('Frecuencia (Hz)')\n",
    "ax[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5148b02e",
   "metadata": {},
   "source": [
    "Y se muestan el tamaño de los archivos de audio como se puede ver el comprimido ocupa menos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc51cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('El tamaño del archivo de audio en mono sin comprimir es:')\n",
    "!ls -sh Audio_output/game_of_thrones_mono.wav\n",
    "print('El tamaño del archivo de audio en mono comprimido es:')\n",
    "!ls -sh Audio_output/game_of_thrones_compressed.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c47c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(audio_data_mono, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c9abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(new_audio_data, rate=new_sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Jupyter",
   "language": "python",
   "name": "mi_entorno"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
